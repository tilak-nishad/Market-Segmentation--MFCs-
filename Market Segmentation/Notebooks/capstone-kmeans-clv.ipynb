{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from __future__ import division\n",
    "from datetime import datetime, timedelta,date\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "#import chart_studio.plotly as py\n",
    "#import plotly.offline as pyoff\n",
    "#import plotly.graph_objs as go\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime,date\n",
    "import calendar\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from lifetimes.datasets import load_cdnow_summary_data_with_monetary_value\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report\n",
    "from lifetimes.utils  import summary_data_from_transaction_data\n",
    "from sklearn.cluster import KMeans\n",
    "import datetime as dt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Lifetimes\n",
      "  Downloading https://files.pythonhosted.org/packages/c5/1f/ee6a471dcb5cb2f4dbc219023e07991f3b917875f9c8a5f5d77c00ddabca/Lifetimes-0.11.3-py3-none-any.whl (584kB)\n",
      "Collecting autograd>=1.2.0 (from Lifetimes)\n",
      "  Downloading https://files.pythonhosted.org/packages/23/12/b58522dc2cbbd7ab939c7b8e5542c441c9a06a8eccb00b3ecac04a739896/autograd-1.3.tar.gz\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from Lifetimes) (0.24.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from Lifetimes) (1.2.1)\n",
      "Requirement already satisfied: dill>=0.2.6 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from Lifetimes) (0.3.0)\n",
      "Requirement already satisfied: numpy>=1.10.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from Lifetimes) (1.16.4)\n",
      "Requirement already satisfied: future>=0.15.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from autograd>=1.2.0->Lifetimes) (0.17.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->Lifetimes) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->Lifetimes) (2019.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\appdata\\roaming\\python\\python37\\site-packages (from python-dateutil>=2.5.0->pandas>=0.24.0->Lifetimes) (1.12.0)\n",
      "Building wheels for collected packages: autograd\n",
      "  Building wheel for autograd (setup.py): started\n",
      "  Building wheel for autograd (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\admin\\AppData\\Local\\pip\\Cache\\wheels\\42\\62\\66\\1121afe23ff96af4e452e0d15e68761e3f605952ee075ca99f\n",
      "Successfully built autograd\n",
      "Installing collected packages: autograd, Lifetimes\n",
      "Successfully installed Lifetimes-0.11.3 autograd-1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install Lifetimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pyoff' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-1190ed86dc55>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#initate plotly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpyoff\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_notebook_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pyoff' is not defined"
     ]
    }
   ],
   "source": [
    "#initate plotly\n",
    "pyoff.init_notebook_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/Administrator/Desktop/FirstChoice/Blended_Data_Features_Removed.csv', low_memory=False)\n",
    "df['Invoice Date']= pd.to_datetime(df['Invoice Date']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['InvoiceDay'] = df['Invoice Date'].apply(lambda x: dt.datetime(x.year, x.month, x.day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the time period\n",
    "print('Min : {}, Max : {}'.format(min(df['InvoiceDay']), max(df['InvoiceDay'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pin the last date\n",
    "pin_date = max(df['Invoice Date']) + dt.timedelta(1)\n",
    "print(pin_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RFM values\n",
    "rfm = df.groupby('Customer No.').agg({\n",
    "    'Invoice Date' : lambda x: (pin_date - x.max()).days,\n",
    "    'Job Card No' : 'count', \n",
    "    'Total Amt Wtd Tax.' : 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the columns\n",
    "rfm.rename(columns = {'Invoice Date' : 'Recency', \n",
    "                      'Job Card No' : 'Frequency', \n",
    "                      'Total Amt Wtd Tax.' : 'Monetary'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot RFM distributions\n",
    "plt.figure(figsize=(12,10))\n",
    "# Plot distribution of R\n",
    "plt.subplot(3, 1, 1); sns.distplot(rfm['Recency'])\n",
    "# Plot distribution of F\n",
    "plt.subplot(3, 1, 2); sns.distplot(rfm['Frequency'])\n",
    "# Plot distribution of M\n",
    "plt.subplot(3, 1, 3); sns.distplot(rfm['Monetary'])\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(rfm[['Recency']])\n",
    "rfm['R'] = kmeans.predict(rfm[['Recency']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(rfm[['Frequency']])\n",
    "rfm['F'] = kmeans.predict(rfm[['Frequency']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rfm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-e3d955772234>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mkmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mkmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrfm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Monetary'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mrfm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'M'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrfm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Monetary'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rfm' is not defined"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(rfm[['Monetary']])\n",
    "rfm['M'] = kmeans.predict(rfm[['Monetary']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat RFM KMeans Cluster values to create RFM Segments\n",
    "def join_rfm(x): return str(x['R'])+str(x['F'])+str(x['M'])\n",
    "rfm['RFM_Segment_Concat'] = rfm.apply(join_rfm, axis=1)\n",
    "rfm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count num of unique segments\n",
    "rfm_count_unique = rfm.groupby('RFM_Segment_Concat')['RFM_Segment_Concat'].nunique()\n",
    "print(rfm_count_unique.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RFM_Score\n",
    "rfm['RFM_Score'] = rfm[['R','F','M']].sum(axis=1)\n",
    "print(rfm['RFM_Score'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm.RFM_Score.value_counts(sort=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define rfm_level function\n",
    "def rfm_level(df):\n",
    "    if df['RFM_Score'] >= 6:\n",
    "        return 'High Segment'\n",
    "    elif ((df['RFM_Score'] >= 3) and (df['RFM_Score'] < 6)):\n",
    "        return 'Mid Segment'\n",
    "    else:\n",
    "        return 'Low Segment'\n",
    "\n",
    "# Create a new variable RFM_Level\n",
    "rfm['RFM_Level'] = rfm.apply(rfm_level, axis=1)\n",
    "# Print the header with top 5 rows to the console\n",
    "rfm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average values for each RFM_Level, and return a size of each segment \n",
    "rfm_level_agg = rfm.groupby('RFM_Level').agg({\n",
    "    'Recency': 'mean',\n",
    "    'Frequency': 'mean',\n",
    "    'Monetary': ['mean', 'count']\n",
    "}).round(1)\n",
    "# Print the aggregated dataset\n",
    "print(rfm_level_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import squarify\n",
    "# rfm_level_agg.columns = rfm_level_agg.columns.droplevel()\n",
    "rfm_level_agg.columns = ['RecencyMean','FrequencyMean','MonetaryMean', 'Count']\n",
    "#Create our plot and resize it.\n",
    "fig = plt.gcf()\n",
    "ax = fig.add_subplot()\n",
    "fig.set_size_inches(16, 9)\n",
    "squarify.plot(sizes=rfm_level_agg['Count'], \n",
    "              label=['High Segment',\n",
    "                     'Mid Segment',\n",
    "                     'Low Segment'], alpha=.6 )\n",
    "plt.title(\"RFM Segments\",fontsize=55,fontweight=\"bold\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = {'High Segment':0, 'Mid Segment':1, 'Low Segment':2}\n",
    "rfm['RFM_Level'] = rfm['RFM_Level'].map(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rfm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm.drop(columns=['R','F','M','RFM_Segment_Concat'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = rfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.drop(columns=['RFM_Score'], inplace=True)\n",
    "temp.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictors\n",
    "X = temp.iloc[:,:-1]\n",
    "# Target\n",
    "y = temp.iloc[:,-1]\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "auc = roc_auc_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'temp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-dbbffd52ecfa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;31m# Predictors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;31m# Target\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'temp' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler,StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier ,RandomForestClassifier ,GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier \n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import Ridge,Lasso\n",
    "from sklearn.metrics import roc_auc_score ,mean_squared_error,accuracy_score,classification_report,roc_curve,confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy.stats.mstats import winsorize\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_columns',None)\n",
    "\n",
    "def run_model(predictors,target, model):\n",
    "    '''\n",
    "    Performs model training and tests using ROC-AUC \n",
    "    returns AUC score\n",
    "    '''\n",
    "    x_train,x_val,y_train,y_val = train_test_split(predictors,target,test_size=0.2,random_state=42)\n",
    "    model.fit(x_train, y_train)\n",
    "    y_scores = model.predict(x_val)\n",
    "    auc = roc_auc_score(y_val, y_scores)\n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_val,y_scores))\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_val, y_scores)\n",
    "    print('ROC_AUC_SCORE is',roc_auc_score(y_val, y_scores))\n",
    "    \n",
    "    #fpr, tpr, _ = roc_curve(y_test, predictions[:,1])\n",
    "    \n",
    "    plt.plot(false_positive_rate, true_positive_rate)\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    "    plt.title('ROC curve')\n",
    "    plt.show()\n",
    "    return auc\n",
    "\n",
    "# Predictors\n",
    "X = temp.iloc[:,:-1]\n",
    "\n",
    "# Target\n",
    "y = temp.iloc[:,-1]\n",
    "\n",
    "# Choosing the models. If you want to specify additional models, kindly specify them as a key-value pair as shown below.\n",
    "models = {'Logistic Regression':LogisticRegression,'Decision Tree':DecisionTreeClassifier,'Random Forest': RandomForestClassifier,'XGBoost':XGBClassifier,'Gradient Boosting':GradientBoostingClassifier}\n",
    "\n",
    "for i in models.items():\n",
    "    # run model\n",
    "    model = i[1]()\n",
    "    print('~~~~~~Running for model '+str(model)+'~~~~~~')\n",
    "    auc = run_model(X, y, model) # train and returns AUC test score\n",
    "    print('AUC Score = %.2f' %(auc*100) +' %\\nOn Model - \\n'+str(i[0]))\n",
    "    print('===='*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Invoice Date':'InvoiceDate'},inplace=True)\n",
    "df.rename(columns={'Total Amt Wtd Tax.':'Revenue'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary=summary_data_from_transaction_data(df,'Customer No.','InvoiceDate',monetary_value_col='Revenue',observation_period_end='2016')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifetimes import BetaGeoFitter\n",
    "bgf=BetaGeoFitter(penalizer_coef=0.0)\n",
    "bgf.fit(summary['frequency'],summary['recency'],summary['T'])\n",
    "print(bgf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=10\n",
    "\n",
    "summary['pred_num']=round(bgf.conditional_expected_number_of_purchases_up_to_time(t,summary['frequency'],summary['recency'], summary['T']),2)\n",
    "summary.sort_values(by='pred_num', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifetimes.plotting import plot_period_transactions\n",
    "plot_period_transactions(bgf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary[['monetary_value', 'frequency']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shortlist customers who had at least one repeat purchase with the company. \n",
    "shortlisted_customers = summary[summary['frequency']>0]\n",
    "print(shortlisted_customers.head().reset_index())\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"The Number of Returning Customers are: \",len(shortlisted_customers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortlisted_customers = shortlisted_customers[shortlisted_customers['monetary_value']>0]\n",
    "shortlisted_customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifetimes import GammaGammaFitter\n",
    "ggf = GammaGammaFitter(penalizer_coef = 0)\n",
    "ggf.fit(shortlisted_customers['frequency'],\n",
    "        shortlisted_customers['monetary_value'])\n",
    "print(ggf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After applying Gamma-Gamma model, now we can estimate average transaction value for each customer. \n",
    "print(ggf.conditional_expected_average_profit(\n",
    "        summary['frequency'],\n",
    "        summary['monetary_value']\n",
    "    ).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary['pred_txn_value'] = round(ggf.conditional_expected_average_profit(\n",
    "        summary['frequency'],\n",
    "        summary['monetary_value']), 2)\n",
    "summary.reset_index().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Customer Lifetime Value\n",
    "summary['CLV'] = round(ggf.customer_lifetime_value(\n",
    "    bgf, #the model to use to predict the number of future transactions\n",
    "    summary['frequency'],\n",
    "    summary['recency'],\n",
    "    summary['T'],\n",
    "    summary['monetary_value'],\n",
    "    time=12, # months\n",
    "    discount_rate=0.01 # monthly discount rate ~ 12.7% annually\n",
    "), 2)\n",
    "\n",
    "summary.drop(summary.iloc[:, 0:6], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.sort_values(by='CLV', ascending=False).head(10).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clv=pd.merge(rfm,summary,on='Customer No.',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clv['no']=np.arange(len(clv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer=clv[['Customer No.','no']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clv.drop('Customer No.',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=clv.drop('RFM_Level',axis=1)\n",
    "y=clv[['RFM_Level']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(y_test, predictions, average='weighted'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=pd.merge(clv,customer,on='no',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initate plotly\n",
    "pyoff.init_notebook_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/Administrator/Desktop/FirstChoice/Blended_Data_Features_Removed.csv', low_memory=False)\n",
    "df['Invoice Date']= pd.to_datetime(df['Invoice Date']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['InvoiceDay'] = df['Invoice Date'].apply(lambda x: dt.datetime(x.year, x.month, x.day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the time period\n",
    "print('Min : {}, Max : {}'.format(min(df['InvoiceDay']), max(df['InvoiceDay'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pin the last date\n",
    "pin_date = max(df['Invoice Date']) + dt.timedelta(1)\n",
    "print(pin_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RFM values\n",
    "rfm = df.groupby('Customer No.').agg({\n",
    "    'Invoice Date' : lambda x: (pin_date - x.max()).days,\n",
    "    'Job Card No' : 'count', \n",
    "    'Total Amt Wtd Tax.' : 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the columns\n",
    "rfm.rename(columns = {'Invoice Date' : 'Recency', \n",
    "                      'Job Card No' : 'Frequency', \n",
    "                      'Total Amt Wtd Tax.' : 'Monetary'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot RFM distributions\n",
    "plt.figure(figsize=(12,10))\n",
    "# Plot distribution of R\n",
    "plt.subplot(3, 1, 1); sns.distplot(rfm['Recency'])\n",
    "# Plot distribution of F\n",
    "plt.subplot(3, 1, 2); sns.distplot(rfm['Frequency'])\n",
    "# Plot distribution of M\n",
    "plt.subplot(3, 1, 3); sns.distplot(rfm['Monetary'])\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(rfm[['Recency']])\n",
    "rfm['R'] = kmeans.predict(rfm[['Recency']])kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(rfm[['Frequency']])\n",
    "rfm['F'] = kmeans.predict(rfm[['Frequency']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(rfm[['Monetary']])\n",
    "rfm['M'] = kmeans.predict(rfm[['Monetary']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat RFM KMeans Cluster values to create RFM Segments\n",
    "def join_rfm(x): return str(x['R'])+str(x['F'])+str(x['M'])\n",
    "rfm['RFM_Segment_Concat'] = rfm.apply(join_rfm, axis=1)\n",
    "rfm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count num of unique segments\n",
    "rfm_count_unique = rfm.groupby('RFM_Segment_Concat')['RFM_Segment_Concat'].nunique()\n",
    "print(rfm_count_unique.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RFM_Score\n",
    "rfm['RFM_Score'] = rfm[['R','F','M']].sum(axis=1)\n",
    "print(rfm['RFM_Score'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm.RFM_Score.value_counts(sort=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define rfm_level function\n",
    "def rfm_level(df):\n",
    "    if df['RFM_Score'] >= 6:\n",
    "        return 'High Segment'\n",
    "    elif ((df['RFM_Score'] >= 3) and (df['RFM_Score'] < 6)):\n",
    "        return 'Mid Segment'\n",
    "    else:\n",
    "        return 'Low Segment'\n",
    "\n",
    "# Create a new variable RFM_Level\n",
    "rfm['RFM_Level'] = rfm.apply(rfm_level, axis=1)\n",
    "# Print the header with top 5 rows to the console\n",
    "rfm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average values for each RFM_Level, and return a size of each segment \n",
    "rfm_level_agg = rfm.groupby('RFM_Level').agg({\n",
    "    'Recency': 'mean',\n",
    "    'Frequency': 'mean',\n",
    "    'Monetary': ['mean', 'count']\n",
    "}).round(1)\n",
    "# Print the aggregated dataset\n",
    "print(rfm_level_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import squarify\n",
    "# rfm_level_agg.columns = rfm_level_agg.columns.droplevel()\n",
    "rfm_level_agg.columns = ['RecencyMean','FrequencyMean','MonetaryMean', 'Count']\n",
    "#Create our plot and resize it.\n",
    "fig = plt.gcf()\n",
    "ax = fig.add_subplot()\n",
    "fig.set_size_inches(16, 9)\n",
    "squarify.plot(sizes=rfm_level_agg['Count'], \n",
    "              label=['High Segment',\n",
    "                     'Mid Segment',\n",
    "                     'Low Segment'], alpha=.6 )\n",
    "plt.title(\"RFM Segments\",fontsize=55,fontweight=\"bold\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = {'High Segment':0, 'Mid Segment':1, 'Low Segment':2}\n",
    "rfm['RFM_Level'] = rfm['RFM_Level'].map(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm.drop(columns=['R','F','M','RFM_Segment_Concat'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = rfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.drop(columns=['RFM_Score'], inplace=True)\n",
    "temp.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictors\n",
    "X = temp.iloc[:,:-1]\n",
    "# Target\n",
    "y = temp.iloc[:,-1]\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "auc = roc_auc_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler,StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier ,RandomForestClassifier ,GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier \n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import Ridge,Lasso\n",
    "from sklearn.metrics import roc_auc_score ,mean_squared_error,accuracy_score,classification_report,roc_curve,confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy.stats.mstats import winsorize\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_columns',None)\n",
    "\n",
    "def run_model(predictors,target, model):\n",
    "    '''\n",
    "    Performs model training and tests using ROC-AUC \n",
    "    returns AUC score\n",
    "    '''\n",
    "    x_train,x_val,y_train,y_val = train_test_split(predictors,target,test_size=0.2,random_state=42)\n",
    "    model.fit(x_train, y_train)\n",
    "    y_scores = model.predict(x_val)\n",
    "    auc = roc_auc_score(y_val, y_scores)\n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_val,y_scores))\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_val, y_scores)\n",
    "    print('ROC_AUC_SCORE is',roc_auc_score(y_val, y_scores))\n",
    "    \n",
    "    #fpr, tpr, _ = roc_curve(y_test, predictions[:,1])\n",
    "    \n",
    "    plt.plot(false_positive_rate, true_positive_rate)\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    "    plt.title('ROC curve')\n",
    "    plt.show()\n",
    "    return auc\n",
    "\n",
    "# Predictors\n",
    "X = temp.iloc[:,:-1]\n",
    "\n",
    "# Target\n",
    "y = temp.iloc[:,-1]\n",
    "\n",
    "# Choosing the models. If you want to specify additional models, kindly specify them as a key-value pair as shown below.\n",
    "models = {'Logistic Regression':LogisticRegression,'Decision Tree':DecisionTreeClassifier,'Random Forest': RandomForestClassifier,'XGBoost':XGBClassifier,'Gradient Boosting':GradientBoostingClassifier}\n",
    "\n",
    "for i in models.items():\n",
    "    # run model\n",
    "    model = i[1]()\n",
    "    print('~~~~~~Running for model '+str(model)+'~~~~~~')\n",
    "    auc = run_model(X, y, model) # train and returns AUC test score\n",
    "    print('AUC Score = %.2f' %(auc*100) +' %\\nOn Model - \\n'+str(i[0]))\n",
    "    print('===='*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Invoice Date':'InvoiceDate'},inplace=True)\n",
    "df.rename(columns={'Total Amt Wtd Tax.':'Revenue'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary=summary_data_from_transaction_data(df,'Customer No.','InvoiceDate',monetary_value_col='Revenue',observation_period_end='2016')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifetimes import BetaGeoFitter\n",
    "bgf=BetaGeoFitter(penalizer_coef=0.0)\n",
    "bgf.fit(summary['frequency'],summary['recency'],summary['T'])\n",
    "print(bgf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=10\n",
    "\n",
    "summary['pred_num']=round(bgf.conditional_expected_number_of_purchases_up_to_time(t,summary['frequency'],summary['recency'], summary['T']),2)\n",
    "summary.sort_values(by='pred_num', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifetimes.plotting import plot_period_transactions\n",
    "plot_period_transactions(bgf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary[['monetary_value', 'frequency']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shortlist customers who had at least one repeat purchase with the company. \n",
    "shortlisted_customers = summary[summary['frequency']>0]\n",
    "print(shortlisted_customers.head().reset_index())\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"The Number of Returning Customers are: \",len(shortlisted_customers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortlisted_customers = shortlisted_customers[shortlisted_customers['monetary_value']>0]\n",
    "shortlisted_customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifetimes import GammaGammaFitter\n",
    "ggf = GammaGammaFitter(penalizer_coef = 0)\n",
    "ggf.fit(shortlisted_customers['frequency'],\n",
    "        shortlisted_customers['monetary_value'])\n",
    "print(ggf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After applying Gamma-Gamma model, now we can estimate average transaction value for each customer. \n",
    "print(ggf.conditional_expected_average_profit(\n",
    "        summary['frequency'],\n",
    "        summary['monetary_value']\n",
    "    ).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary['pred_txn_value'] = round(ggf.conditional_expected_average_profit(\n",
    "        summary['frequency'],\n",
    "        summary['monetary_value']), 2)\n",
    "summary.reset_index().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Customer Lifetime Value\n",
    "summary['CLV'] = round(ggf.customer_lifetime_value(\n",
    "    bgf, #the model to use to predict the number of future transactions\n",
    "    summary['frequency'],\n",
    "    summary['recency'],\n",
    "    summary['T'],\n",
    "    summary['monetary_value'],\n",
    "    time=12, # months\n",
    "    discount_rate=0.01 # monthly discount rate ~ 12.7% annually\n",
    "), 2)\n",
    "\n",
    "summary.drop(summary.iloc[:, 0:6], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.sort_values(by='CLV', ascending=False).head(10).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clv=pd.merge(rfm,summary,on='Customer No.',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clv['no']=np.arange(len(clv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer=clv[['Customer No.','no']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clv.drop('Customer No.',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=clv.drop('RFM_Level',axis=1)\n",
    "y=clv[['RFM_Level']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(y_test, predictions, average='weighted'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=pd.merge(clv,customer,on='no',how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLV DONE FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime,date\n",
    "import calendar\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from lifetimes.datasets import load_cdnow_summary_data_with_monetary_value\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report\n",
    "from lifetimes.utils  import summary_data_from_transaction_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer=pd.read_csv('C:/Users/Administrator/Desktop/FirstChoice/Customer1.csv')\n",
    "invoice=pd.read_csv('C:/Users/Administrator/Desktop/FirstChoice/Final_invoice.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoice.rename(columns={'Custor No.':'Customer No.'},inplace=True)\n",
    "invoice['Customer No.']=invoice['Customer No.'].apply(lambda x:x.strip())\n",
    "customer['Customer No.']=customer['Customer No.'].apply(lambda x:str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join=pd.merge(customer[['Customer No.','Business Partner','Occuption']],invoice[['Area / Locality','CITY','Claim No.','Cust Type','Customer No.','District','Insurance Company','Invoice Date','Job Card No','JobCard Date','KMs Reading','Make','Model','Pin code','ODN No.','Order Type','Plant Name1','Regn No','Total Amt Wtd Tax.']],how='inner', on ='Customer No.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join.isnull().sum()\n",
    "join['occuption']=join['occuption'].apply(lambda x:'Others' if x=='0' else x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join['District']=join['District'].apply(lambda x:str(x))\n",
    "join['District']=join['District'].apply(lambda x:x.lower())\n",
    "city=join['District'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join['Model']=join['Model'].fillna(value='Others')\n",
    "join['Insurance Company']=join['Insurance Company'].fillna(value='Others')\n",
    "#join.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join['Invoice Date']=join['Invoice Date'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d').date()) \n",
    "join['monthno']=join['Invoice Date'].apply(lambda x:x.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join['month']=join['monthno'].apply(lambda x:calendar.month_name[x])\n",
    "join.rename(columns={'Invoice Date':'InvoiceDate'},inplace=True)\n",
    "join.rename(columns={'Total Amt Wtd Tax.':'Revenue'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary=summary_data_from_transaction_data(join,'Customer No.','InvoiceDate',monetary_value_col='Revenue',observation_period_end='2016')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary['frequency'].plot(kind='hist',bins=50)\n",
    "print(summary['frequency'].describe())\n",
    "one_time_buyer=round(sum(summary['frequency']==0)/float(len(summary))*(100),2)\n",
    "print('one time buyer: ',one_time_buyer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifetimes import BetaGeoFitter\n",
    "bgf=BetaGeoFitter(penalizer_coef=0.0)\n",
    "bgf.fit(summary['frequency'],summary['recency'],summary['T'])\n",
    "print(bgf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgf.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=10\n",
    "\n",
    "summary['pred_num']=round(bgf.conditional_expected_number_of_purchases_up_to_time(t,summary['frequency'],summary['recency'], summary['T']),2)\n",
    "summary.sort_values(by='pred_num', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifetimes.plotting import plot_period_transactions\n",
    "plot_period_transactions(bgf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t = 500\n",
    "individual = summary.loc[1]\n",
    "bgf.predict(t, individual['frequency'], individual['recency'], individual['T'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary[['monetary_value', 'frequency']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shortlist customers who had at least one repeat purchase with the company. \n",
    "shortlisted_customers = summary[summary['frequency']>0]\n",
    "print(shortlisted_customers.head().reset_index())\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"The Number of Returning Customers are: \",len(shortlisted_customers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortlisted_customers = shortlisted_customers[shortlisted_customers['monetary_value']>0]\n",
    "shortlisted_customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
